
from google.colab import drive

drive.mount('/content/drive', force_remount=True)

# enter the foldername in your Drive where you have saved the unzipped
# 'cs231n' folder containing the '.py', 'classifiers' and 'datasets'
# folders.
# e.g. 'cs231n/assignments/assignment1/cs231n/'
FOLDERNAME = 'ML_Colab_CS231/assignment1/cs231n/'

assert FOLDERNAME is not None, "[!] Enter the foldername."

%cd /content/drive/My\ Drive
# %cp -r $FOLDERNAME ../../
# %cd ../../
# %cd cs231n/datasets/
%cd $FOLDERNAME/datasets/
!bash get_datasets.sh
%cd ../../

import random
import numpy as np
from cs231n.data_utils import load_CIFAR10
import matplotlib.pyplot as plt


%matplotlib inline
plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots
plt.rcParams['image.interpolation'] = 'nearest'
plt.rcParams['image.cmap'] = 'gray'

# for auto-reloading extenrnal modules
# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython
%load_ext autoreload
%autoreload 2

from cs231n.features import color_histogram_hsv, hog_feature

def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):
    # Load the raw CIFAR-10 data
    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'

    # Cleaning up variables to prevent loading data multiple times (which may cause memory issue)
    try:
       del X_train, y_train
       del X_test, y_test
       print('Clear previously loaded data.')
    except:
       pass

    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)
    
    # Subsample the data
    mask = list(range(num_training, num_training + num_validation))
    X_val = X_train[mask]
    y_val = y_train[mask]
    mask = list(range(num_training))
    X_train = X_train[mask]
    y_train = y_train[mask]
    mask = list(range(num_test))
    X_test = X_test[mask]
    y_test = y_test[mask]
    
    return X_train, y_train, X_val, y_val, X_test, y_test

X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()

from cs231n.features import *

num_color_bins = 10 # Number of bins in the color histogram
feature_fns = [hog_feature, lambda img: color_histogram_hsv(img, nbin=num_color_bins)]
X_train_feats = extract_features(X_train, feature_fns, verbose=True)
X_val_feats = extract_features(X_val, feature_fns)
X_test_feats = extract_features(X_test, feature_fns)

# Preprocessing: Subtract the mean feature
mean_feat = np.mean(X_train_feats, axis=0, keepdims=True)
X_train_feats -= mean_feat
X_val_feats -= mean_feat
X_test_feats -= mean_feat

# Preprocessing: Divide by standard deviation. This ensures that each feature
# has roughly the same scale.
std_feat = np.std(X_train_feats, axis=0, keepdims=True)
X_train_feats /= std_feat
X_val_feats /= std_feat
X_test_feats /= std_feat

# Preprocessing: Add a bias dimension
X_train_feats = np.hstack([X_train_feats, np.ones((X_train_feats.shape[0], 1))])
X_val_feats = np.hstack([X_val_feats, np.ones((X_val_feats.shape[0], 1))])
X_test_feats = np.hstack([X_test_feats, np.ones((X_test_feats.shape[0], 1))])

# Use the validation set to tune the learning rate and regularization strength

from cs231n.classifiers.linear_classifier import LinearSVM

learning_rates = [1e-9, 1e-8, 1e-7]
regularization_strengths = [5e4, 5e5, 5e6]

results = {}
best_val = -1
best_svm = None

################################################################################
# TODO:                                                                        #
# Use the validation set to set the learning rate and regularization strength. #
# This should be identical to the validation that you did for the SVM; save    #
# the best trained classifer in best_svm. You might also want to play          #
# with different numbers of bins in the color histogram. If you are careful    #
# you should be able to get accuracy of near 0.44 on the validation set.       #
################################################################################
# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****

# learning_rates = []
# regularisation_strengths = []

valed_lrs = learning_rates  # np.logspace( np.log10(learning_rates[0]), np.log10(learning_rates[-1]), num=6)
valed_regs = regularization_strengths  # np.logspace( np.log10(regularisation_strengths[0]), np.log10(regularisation_strengths[-1]), num=6)

import itertools

for lr, reg in itertools.product(valed_lrs, valed_regs):
  svm = LinearSVM()
  svm.train(X_train_feats, y_train)
  train_acc = (svm.predict(X_train_feats) == y_train).mean()
  val_acc = (svm.predict(X_val_feats) == y_val).mean()

  results[(lr, reg)] = (train_acc, val_acc)
  
  if val_acc > best_val:
    best_val = val_acc
    best_svm = svm

# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****

# Print out results.
for lr, reg in sorted(results):
    train_accuracy, val_accuracy = results[(lr, reg)]
    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (
                lr, reg, train_accuracy, val_accuracy))
    
print('best validation accuracy achieved during cross-validation: %f' % best_val)

# Evaluate your trained SVM on the test set: you should be able to get at least 0.40
y_test_pred = best_svm.predict(X_test_feats)
test_accuracy = np.mean(y_test == y_test_pred)
print(test_accuracy)

# An important way to gain intuition about how an algorithm works is to
# visualize the mistakes that it makes. In this visualization, we show examples
# of images that are misclassified by our current system. The first column
# shows images that our system labeled as "plane" but whose true label is
# something other than "plane".

examples_per_class = 8
classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
for cls, cls_name in enumerate(classes):
    idxs = np.where((y_test != cls) & (y_test_pred == cls))[0]
    idxs = np.random.choice(idxs, examples_per_class, replace=False)
    for i, idx in enumerate(idxs):
        plt.subplot(examples_per_class, len(classes), i * len(classes) + cls + 1)
        plt.imshow(X_test[idx].astype('uint8'))
        plt.axis('off')
        if i == 0:
            plt.title(cls_name)
plt.show()

# Preprocessing: Remove the bias dimension
# Make sure to run this cell only ONCE
print(X_train_feats.shape)
X_train_feats = X_train_feats[:, :-1]
X_val_feats = X_val_feats[:, :-1]
X_test_feats = X_test_feats[:, :-1]

print(X_train_feats.shape)

from cs231n.classifiers.neural_net import TwoLayerNet

input_dim = X_train_feats.shape[1]
hidden_dim = 500
num_classes = 10

net = TwoLayerNet(input_dim, hidden_dim, num_classes)
best_net = None

################################################################################
# TODO: Train a two-layer neural network on image features. You may want to    #
# cross-validate various parameters as in previous sections. Store your best   #
# model in the best_net variable.                                              #
################################################################################
# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****

hidden_sizes = [100, 1000]
learning_rates = [1e-1, 3e0]
regs = [3e-4, 3e-3]
batch_epoch_ratio = [200/49000, 0.4]

valed_hidden_sizes = np.array([400])
#valed_lrs = np.logspace( np.log10(learning_rates[0]), np.log10(learning_rates[1]), num=5)
#valed_regs = np.logspace( np.log10(regs[0]), np.log10(regs[1]), num=5)
valed_lrs = np.array([8.25e-01])  # np.linspace( learning_rates[0], learning_rates[1], num=5)
valed_regs = np.array([9.75e-04])  # np.linspace(regs[0], regs[1], num=5)
valed_brs = np.array([200/49000])

import itertools

num_trains = X_train_feats.shape[0]
num_epochs = 16000*200/49000  # N.B. num_epochs * num_trains = batch_size * num_iters => num_epochs = br * num_iters

best_val_acc = -1
stats = None
results = {}

num_combinations = len(valed_hidden_sizes)*len(valed_lrs)*len(valed_regs)*len(valed_brs)
combi = 1

for hs, lr, reg, br in itertools.product(valed_hidden_sizes, valed_lrs, valed_regs, valed_brs):

  net = TwoLayerNet(input_dim, hs, num_classes)

  batch_size = np.around( br * num_trains ).astype(int)
  num_iters = np.around( num_epochs / br ).astype(int)

  print('<< COMBI=%d/%d ... HIDDEN_SIZE=%d, LR=%.2e, REG=%.2e, BATCH_RATIO=%.3f ... BATCH_SIZE=%d, NUM_ITERS=%d >>' \
        % (combi, num_combinations, hs, lr, reg, br,  batch_size, num_iters) )
  
  stats = net.train(X_train_feats, y_train, X_val_feats, y_val,
              num_iters=num_iters, batch_size=batch_size,
              learning_rate=lr, learning_rate_decay=0.95,
              reg=reg, verbose=True)
  
  val_acc = (net.predict(X_val_feats) == y_val).mean()
  train_acc = (net.predict(X_train_feats) == y_train).mean()

  if len(valed_brs)*len(valed_hidden_sizes) == 1:
    results[(lr, reg)] = (train_acc, val_acc)

  print('<< TRAIN_ACC=%.2f, VAL_ACC=%.2f >>' % (train_acc, val_acc) )
  print()

  if val_acc > best_val_acc:
    best_val_acc = val_acc
    best_net = net
    best_stats = stats
  
  combi += 1


plt.subplot(2, 1, 1)
plt.plot(best_stats['loss_history'])
plt.title('Loss history')
plt.xlabel('Iteration')
plt.ylabel('Loss')

plt.subplot(2, 1, 2)
plt.plot(best_stats['train_acc_history'], label='train')
plt.plot(best_stats['val_acc_history'], label='val')
plt.title('Classification accuracy history')
plt.xlabel('Epoch')
plt.ylabel('Classification accuracy')
plt.legend()
plt.show()

# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****


val_acc = (best_net.predict(X_val_feats) == y_val).mean()
print('Validation accuracy: ', val_acc)

# Run your best neural net classifier on the test set. You should be able
# to get more than 55% accuracy.

test_acc = (best_net.predict(X_test_feats) == y_test).mean()
print(test_acc)

if len(valed_brs)*len(valed_hidden_sizes) == 1:

  # LCB FROM SVM.IPYNB # Visualize the cross-validation results
  import math
  import pdb

  # pdb.set_trace()

  x_scatter = [math.log10(x[0]) for x in results]
  y_scatter = [math.log10(x[1]) for x in results]

  # plot training accuracy
  marker_size = 100
  colors = [results[x][0] for x in results]
  plt.subplot(2, 1, 1)
  plt.tight_layout(pad=3)
  plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=plt.cm.coolwarm)
  plt.colorbar()
  plt.xlabel('log learning rate')
  plt.ylabel('log regularization strength')
  plt.title('CIFAR-10 training accuracy')

  # plot validation accuracy
  colors = [results[x][1] for x in results] # default size of markers is 20
  plt.subplot(2, 1, 2)
  plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=plt.cm.coolwarm)
  plt.colorbar()
  plt.xlabel('log learning rate')
  plt.ylabel('log regularization strength')
  plt.title('CIFAR-10 validation accuracy')
  plt.show()

import os

FOLDER_TO_SAVE = os.path.join('drive/My Drive/', FOLDERNAME)
FILES_TO_SAVE = []

#for files in FILES_TO_SAVE:
#  with open(os.path.join(FOLDER_TO_SAVE, '/'.join(files.split('/')[1:])), 'w') as f:
#    f.write(''.join(open(files).readlines()))
